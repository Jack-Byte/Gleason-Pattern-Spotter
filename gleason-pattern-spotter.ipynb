{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import io \n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import torchvision.transforms as T\n",
    "import gc\n",
    "from bokeh.plotting import ColumnDataSource, figure, output_notebook, show\n",
    "from bokeh.models import Text, Rect, HoverTool, Range1d\n",
    "import panel as pn\n",
    "from fastai.vision import *\n",
    "from PIL import Image as PILImage\n",
    "from ipywidgets import Label, Button, FileUpload, Output, VBox, AppLayout, Layout, Dropdown\n",
    "from IPython.core.display import HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "VERBOSE=False\n",
    "\n",
    "TEXTS = {\"plot_title\" : {\"en\" : \"Detected Gleason Patterns\", \"de\" : \"Erkannte Gleason Muster\"},\n",
    "         \"dpd_lang\" : {\"en\" : \"Language\", \"de\" : \"Sprache\"},\n",
    "         \"btn_doc\" : {\"en\" : \"Show Documentation\", \"de\" : \"Dokumentation Anzeigen\"},\n",
    "         \"btn_karolinska\" : {\"en\" : \"Karolinksa Sample Biopsy\", \"de\" : \"Karolinksa-Biopsie Beispiel\"},\n",
    "         \"btn_radboud\" : {\"en\" : \"Radboud Sample Biopsy\", \"de\" : \"Radboud-Biopsie Beispiel\"},\n",
    "         \"btn_header\" : {\"en\" : \"Gleason Pattern Spotter\", \"de\" : \"Gleason Pattern Spotter\"},\n",
    "         \"btn_upload\" : {\"en\" : \"Upload Biopsy\", \"de\" : \"Biopsie hochladen\"},\n",
    "         \"btn_status_init\" : {\"en\" : \"\", \"de\" : \"\"},\n",
    "         \"btn_status_progress\" : {\"en\" : \"Processing - \", \"de\" : \"Verarbeitung läuft - \"},\n",
    "         \"btn_status_default\" : {\"en\" : \"Please Wait\", \"de\" : \"Bitte Warten\"},\n",
    "         \"btn_status_load\" : {\"en\" : \"Loading Image\", \"de\" : \"Bild wird geladen\"},\n",
    "         \"btn_status_detect\" : {\"en\" : \"Detecting Gleason Patterns\", \"de\" : \"Gleason Muster werden ausgewertet\"},\n",
    "         \"btn_status_ready\" : {\"en\" : \"Ready For User Input\", \"de\" : \"Bereit für Benutzereingabe\"},\n",
    "         \"btn_status_error\" : {\"en\" : \"Error Loading Image\", \"de\" : \"Fehler beim Abruf des Bildes\"},\n",
    "        }\n",
    "\n",
    "HTML_EN = \"\"\"<div class=\"jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput \" data-mime-type=\"text/markdown\">\n",
    "<h1 id=\"Gleason-Pattern-Spotter\">Gleason Pattern Spotter<a class=\"anchor-link\" href=\"#Gleason-Pattern-Spotter\">¶</a></h1><p>The Gleason Pattern Spotter is a web application that takes a prostate cancer image, divides the image into a grid of several boxes, and then detects the Gleason Pattern for each box.</p>\n",
    "<p>Wait, what is a Gleason Pattern? This application is the result of my approach to the <a href=\"https://www.kaggle.com/c/prostate-cancer-grade-assessment\">PANDA Challenge</a>. Please refer to the <a href=\"https://www.kaggle.com/c/prostate-cancer-grade-assessment\">competition website</a> for more information.</p>\n",
    "<p>Due to bugs in my code I wasn't able to submit the approach to the competition. This application is designed to inspect the image, the boxes and the detected patterns.</p>\n",
    "<p><font size=\"3\" color=\"red\">!!! Please do not take the predicted Gleason patterns for real. The results are likely to be wrong !!!</font></p>\n",
    "<p>By pressing one of the buttons \"Karolinska Biopsy\" or \"Radboud Biopsy\", a random image of the one those Data Providers will be taken, processed and displayed below. (Additionally you can upload your own Biopsy by using the \"Upload Biopsy\" Button).</p>\n",
    "<p>The image and its predictions, will apear below and can be interactively analyzed using the toolbar in the top right corner.</p>\n",
    "<table>\n",
    "<thead><tr>\n",
    "<th>Icon</th>\n",
    "<th>Name</th>\n",
    "<th>Description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td><img src=\"https://docs.bokeh.org/en/latest/_images/Pan.png\" alt=\"\"></td>\n",
    "<td>Pan</td>\n",
    "<td>The pan tool allows the user to pan the plot by left-dragging a mouse or dragging a finger across the plot region.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"https://docs.bokeh.org/en/latest/_images/BoxZoom.png\" alt=\"\"></td>\n",
    "<td>BoxZoom</td>\n",
    "<td>The box zoom tool allows the user to define a rectangular region to zoom the plot bounds to. This is done by left-dragging a mouse, or dragging a finger across the plot area.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"https://docs.bokeh.org/en/latest/_images/WheelZoom.png\" alt=\"\"></td>\n",
    "<td>WheelZoom</td>\n",
    "<td>The wheel zoom tool will zoom the plot in and out, centered on the current mouse location. It will respect any min and max values and ranges, preventing zooming in and out beyond these values.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"https://docs.bokeh.org/en/latest/_images/Save.png\" alt=\"\"></td>\n",
    "<td>Save</td>\n",
    "<td>The save tool pops up a modal dialog that allows the user to save a PNG image of the plot.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"https://docs.bokeh.org/en/latest/_images/Reset.png\" alt=\"\"></td>\n",
    "<td>Reset</td>\n",
    "<td>The reset tool will restore the plot ranges to their original values.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "</div>\"\"\"\n",
    "\n",
    "HTML_DE = \"\"\"<div class=\"jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput \" data-mime-type=\"text/markdown\">\n",
    "<h1 id=\"Gleason-Pattern-Spotter\">Gleason Pattern Spotter<a class=\"anchor-link\" href=\"#Gleason-Pattern-Spotter\">¶</a></h1><p>Der Gleason Pattern Spotter ist eine Webanwendung, die ein Prostatakrebsbild aufnimmt, das Bild in ein Gitter aus mehreren Kästchen unterteilt und dann das Gleason-Muster für jedes Kästchen ermittelt.</p>\n",
    "<p>Was ist ein Gleason-Muster? Diese Anwendung ist das Ergebnis meines Ansatzes bei der <a href=\"https://www.kaggle.com/c/prostate-cancer-grade-assessment\">PANDA Challenge</a>. Weitere Informationen finden Sie auf der <a href=\"https://www.kaggle.com/c/prostate-cancer-grade-assessment\">Wettbewerbs-Website</a>.</p>\n",
    "<p>Aufgrund von Fehlern in meinem Code war es mir nicht möglich, den Ansatz für den Wettbewerb einzureichen. Diese Anwendung dient dazu, das Bild, die Kästchen und die erkannten Muster zu untersuchen.</p>\n",
    "<p><font size=\"3\" color=\"red\">!!! Bitte trauen Sie den ermittelten Gleason-Muster nicht. Die Ergebnisse werden wahrscheinlich fehlerhaft sein !!!</font></p>\n",
    "<p>Durch Drücken einer der Schaltflächen \"Karolinska-Biopsie\" oder \"Radboud-Biopsie\" wird ein zufälliges Bild von demjenigen dieser Datenlieferanten aufgenommen, verarbeitet und unten angezeigt. (Zusätzlich können Sie Ihre eigene Biopsie hochladen, indem Sie den Button \"Biopsie hochladen\" betätigen).</p>\n",
    "<p>Das Bild und seine Vorhersagen können interaktiv mit Hilfe der Symbolleiste in der oberen rechten Ecke des Diagramms analysiert werden.</p>\n",
    "<table>\n",
    "<thead><tr>\n",
    "<th>Icon</th>\n",
    "<th>Name</th>\n",
    "<th>Beschreibung</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td><img src=\"https://docs.bokeh.org/en/latest/_images/Pan.png\" alt=\"\"></td>\n",
    "<td>Verschieben</td>\n",
    "<td>Mit dem Verschieben-Werkzeug kann der Benutzer den das Bild verschieben.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"https://docs.bokeh.org/en/latest/_images/BoxZoom.png\" alt=\"\"></td>\n",
    "<td>Box-Zoom</td>\n",
    "<td>Mit dem Box-Zoom-Werkzeug kann der Benutzer einen rechteckigen Bereich definieren, auf den die Diagrammgrenzen gezoomt werden. Dies geschieht durch Ziehen mit der linken Maustaste oder durch Ziehen mit dem Finger über den Diagrammbereich.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"https://docs.bokeh.org/en/latest/_images/WheelZoom.png\" alt=\"\"></td>\n",
    "<td>Rad-Zoom</td>\n",
    "<td>Mit dem Rad-Zoom-Werkzeug wird die Darstellung ein- und ausgezoomt, zentriert auf die aktuelle Mausposition.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"https://docs.bokeh.org/en/latest/_images/Save.png\" alt=\"\"></td>\n",
    "<td>Speichern</td>\n",
    "<td>Das Speicherwerkzeug öffnet einen Dialog, der es dem Benutzer ermöglicht, ein PNG-Bild des Diagramms zu speichern.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"https://docs.bokeh.org/en/latest/_images/Reset.png\" alt=\"\"></td>\n",
    "<td>Zurücksetzen</td>\n",
    "<td>Das Rücksetzwerkzeug stellt das Diagramm auf ihre ursprünglichen Werte zurück.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "</div>\"\"\"\n",
    "\n",
    "DOC = {\"en\" : HTML_EN,\n",
    "       \"de\" : HTML_DE}\n",
    "\n",
    "lang=\"en\"\n",
    "\n",
    "def accuracy_multi(inp, targ, thresh=0.5, sigmoid=True):\n",
    "    \"Compute accuracy when `inp` and `targ` are the same size.\"\n",
    "    if sigmoid: inp = inp.sigmoid()\n",
    "    return ((inp>thresh)==targ.bool()).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Load model and define prediction function\n",
    "learn = load_learner('', 'trained_model_fastai_resnet50.pkl')\n",
    "\n",
    "def predictPatch(image, x, y, size, confidence):\n",
    "    patch = image.crop((x, y, x+size, y+size))\n",
    "    c, l, preds = learn.predict(Image(T.ToTensor()(patch.convert('RGB'))))\n",
    "    mostconfident = learn.data.classes[preds.argmax()]\n",
    "    pname = ';'.join(cls for cls,onehot in zip(learn.data.classes,l) if onehot==1)\n",
    "    tmp = dict(zip(learn.data.classes, [\"{0:.2%}\".format(p) for p in preds]))\n",
    "    tmp['pred'] = pname\n",
    "    tmp['x'] = x+size//2\n",
    "    tmp['y'] = y+size//2\n",
    "    tmp['line_clr'] = 'grey' if preds.argmax()<confidence else COLORMAP[mostconfident]\n",
    "    \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack to get the dynamic urls of the images\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "IMAGE_PROVIDER_MAP = {'658be675223ffa5509203009eb7bba89.png' : 'radboud',\n",
    "                      'c306e9bf52ed33801003d17ae3f60d32.png' : 'radboud',\n",
    "                      'b0ee38976e71dfbfba705974713ee612.png' : 'radboud',\n",
    "                      '8a21fc0aed2fd06a8b3fe4824c53413e.png' : 'radboud',\n",
    "                      '6a5cc0b66b8d4af9c13f1303c6de5ffb.png' : 'radboud',\n",
    "                      '58d13c5b7c1d86814e7a9451fef0d9d5.png' : 'radboud',\n",
    "                      '36eeee47a868b8ac66b6ece9e6372984.png' : 'radboud',\n",
    "                      '35f629e359399d425289242b698b3f66.png' : 'radboud',\n",
    "                      '345f3e86a3dcc26dce73ceeacc5a4a0a.png' : 'radboud',\n",
    "                      'c4b7ca39cc464a7af7f80fb9f4bc05c3.png' : 'karolinska',\n",
    "                      'acc79fc48cdb1a2c730a0b2c15b0355d.png' : 'karolinska',\n",
    "                      'a6a07e971c280f5cee808a92a5b06e70.png' : 'karolinska',\n",
    "                      '89d137c7fb29df7596e6824181b7d5c9.png' : 'karolinska',\n",
    "                      'fe1d0b156ddba991585791769dc9ede9.png' : 'karolinska',\n",
    "                      '5d35e9a318e04684020a42c3a2ca19fa.png' : 'karolinska',\n",
    "                      '2665dd5db932525f171f931c16112c65.png' : 'karolinska',\n",
    "                      '0d7666fdc3372c68a080c612081e2b45.png' : 'karolinska',\n",
    "                      'fd1deb6f87696b6372ea9c9b109b4ccf.png' : 'karolinska'}\n",
    "\n",
    "provider_urls = {'radboud': [],\n",
    "                 'karolinska': []\n",
    "                }\n",
    "\n",
    "url = \"https://www.kaggle.com/jackbyte/sample-gleason-biopsy-pictures\"\n",
    "hack_failed = False\n",
    "\n",
    "try:\n",
    "    r = urllib.request.urlopen(url).read()\n",
    "\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "\n",
    "    splits = str(soup).split('img')\n",
    "    urls = [s for s in splits if s in [img for img in IMAGE_PROVIDER_MAP]]\n",
    "    len(urls)\n",
    "\n",
    "\n",
    "\n",
    "    splits = str(soup).split(',')\n",
    "\n",
    "    dl_urls = [s[15:-1] for s in splits if 'downloadUrl' in s]\n",
    "\n",
    "    for img in IMAGE_PROVIDER_MAP:\n",
    "        provider = IMAGE_PROVIDER_MAP[img]\n",
    "        for i, url in enumerate(dl_urls):\n",
    "            if img in url:\n",
    "                provider_urls[provider] = provider_urls[provider] + [dl_urls[i]]\n",
    "except:\n",
    "    hack_failed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "# Image and grid functions\n",
    "def getSampleImageFromUrl(provider='radboud'):\n",
    "    \"\"\"Given a 'provider' this function will return an sample/random image\n",
    "    from the notebook https://www.kaggle.com/jackbyte/sample-gleason-biopsy-pictures.\"\"\"\n",
    "    url = random.sample(list(provider_urls[provider]),1)[0]\n",
    "    \n",
    "    return PILImage.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "def calculateGridCoords(w, h, \n",
    "                        max_box_amount=100, \n",
    "                        init_pixels=256,\n",
    "                        max_overlap=0.5):\n",
    "    \"\"\"Given widht 'w' and height 'h' this function will return a list\n",
    "    of the x,y coords of (square) boxes and the pixel size of those boxes.\n",
    "    \n",
    "    The size of the boxes will be 'init_pixels' if the amount of the boxes is\n",
    "    max_box_amount. If not, the size will be doubled until the amount is less\n",
    "    than max_box_amount.\n",
    "    x and ys of thiswithin the\n",
    "    limits of 'w' and 'h'\"\"\"\n",
    "    pixels = init_pixels\n",
    "    coords = [i for i in range(max_box_amount)]\n",
    "    too_many_boxes = True\n",
    "    while too_many_boxes:\n",
    "        \n",
    "        # find x and y positions of box\n",
    "        xes = [i*pixels for i in range(w//pixels)] \n",
    "        ys = [i*pixels for i in range(h//pixels)]\n",
    "        \n",
    "        # Add additional boxes if there is space left\n",
    "        # and the additional box doesn't overlap more\n",
    "        # than 'max_overlap'\n",
    "        if (w%pixels!=0)&((w%pixels)/pixels>max_overlap):\n",
    "            xes = xes + [w-pixels]\n",
    "        if (h%pixels!=0)&((h%pixels)/pixels>max_overlap):\n",
    "            ys = ys + [h-pixels]\n",
    "        \n",
    "        # list of all coordinates that have at least pixel_score pixels that are on the mask\n",
    "        coords = [(x,y) for (x,y) in list(itertools.product(xes, ys)) ]\n",
    "        \n",
    "        \n",
    "        if len(coords)>max_box_amount:\n",
    "            pixels = pixels*2\n",
    "        else:\n",
    "            too_many_boxes = False\n",
    "    \n",
    "    return pixels, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "# cv2 magic for only giving boxes that not white background\n",
    "def maskoff(img, coords, box_size, thr1=200, thr2=200, \n",
    "            krnlr=3,krnlc=3, target_dim=(8192, 26368), \n",
    "            pixel_score=0.25, verbose=False):\n",
    "    \"\"\"Given 'img', 'coords', and 'box_size' this function will  to return \n",
    "    - a resized version of the image\n",
    "    - a matching image mask for the resized image\n",
    "    - a image mask for the original image\n",
    "    - a list of the x,y coords of (square 'box_size(d)') boxes \n",
    "      that overlap with the foreground of the original sized mask\"\"\"\n",
    "    \n",
    "    resized = cv2.resize(img, (256,256), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    edges = cv2.Canny(resized, thr1,thr2)\n",
    "    kernel = np.ones((krnlr,krnlc), np.uint8)\n",
    "    closing = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "    erosion = cv2.morphologyEx(closing, cv2.MORPH_ERODE, kernel, iterations=1)\n",
    "\n",
    "    # When using Grabcut the mask image should be:\n",
    "    #    0 - sure background\n",
    "    #    1 - sure foreground\n",
    "    #    2 - unknown\n",
    "\n",
    "    mask = np.zeros(resized.shape[:2], np.uint8)\n",
    "    mask[:] = 2\n",
    "    mask[erosion == 255] = 1\n",
    "\n",
    "    bgdmodel = np.zeros((1, 65), np.float64)\n",
    "    fgdmodel = np.zeros((1, 65), np.float64)\n",
    "\n",
    "    out_mask = mask.copy()\n",
    "    start = time.time()\n",
    "    if verbose: print('[maskoff] resized.shape', resized.shape)\n",
    "    out_mask, _, _ = cv2.grabCut(resized,out_mask,None,bgdmodel,fgdmodel,1,cv2.GC_INIT_WITH_MASK)\n",
    "    end = time.time()\n",
    "    if verbose: print('[maskoff] grabcut took', end-start)\n",
    "    out_mask = np.where((out_mask==2)|(out_mask==0),0,1).astype('uint8')\n",
    "    \n",
    "    out_mask_small = out_mask.copy()\n",
    "    \n",
    "    out_mask = cv2.resize(out_mask, target_dim, interpolation = cv2.INTER_CUBIC)\n",
    "    \n",
    "    # list of all coordinates that have at least pixel_score pixels that are on the mask\n",
    "    out_coords = [(x,y) for (x,y) in coords if out_mask[y:y+box_size,x:x+box_size].sum()/(box_size*box_size)>pixel_score]\n",
    "    \n",
    "    return resized, out_mask_small, out_mask, out_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "# data viz stuff\n",
    "TOOLTIPS = [(\"Classification\", \"@pred\"),\n",
    "            (\"Gleason_3 confidence\", \"@Gleason_3\"),\n",
    "            (\"Gleason_4 confidence\", \"@Gleason_4\"),\n",
    "            (\"Gleason_5 confidence\", \"@Gleason_5\"),\n",
    "            (\"benign_epithelium confidence\", \"@benign_epithelium\"),\n",
    "           ]\n",
    "\n",
    "class_confidence = [(f'{c}  confidence', f'@{{{c}}}')for c in learn.data.classes]\n",
    "TOOLTIPS = [(\"Classification\", \"@pred\")] + class_confidence\n",
    "\n",
    "\n",
    "COLORMAP = {'Gleason3': 'yellow',\n",
    "            'Gleason4': 'salmon',\n",
    "            'Gleason5': 'red',\n",
    "            'benign epithelium': 'forestgreen',\n",
    "            'stroma': 'forestgreen'}\n",
    "\n",
    "\n",
    "def bokehplotImage(image, grayscale=False):\n",
    "    if grayscale:\n",
    "        image= image.convert(\"L\")\n",
    "    \n",
    "    # resize the image \n",
    "    w, h = image.size\n",
    "    while w*h>2**21:\n",
    "        image.thumbnail(size=[v//2 for v in image.size])\n",
    "        w, h = image.size\n",
    "    \n",
    "    p = figure(sizing_mode='stretch_both',\n",
    "               title=TEXTS[\"plot_title\"][lang],\n",
    "               output_backend=\"webgl\")\n",
    "    p.x_range=(Range1d(0,p.plot_width))\n",
    "    p.y_range=(Range1d(0,p.plot_height))\n",
    "    im = image.convert(\"RGBA\")\n",
    "    # convert to numpy and flip (https://github.com/bokeh/bokeh/issues/1666)\n",
    "    imarray = np.array(im)[::-1]\n",
    "    \n",
    "    p.image_rgba(image=[imarray], x=0,y=0, dw=w, dh=h)\n",
    "    \n",
    "    return p\n",
    "\n",
    "def bokehplotPatterns(image, confidence=0.7,  filename=None, verbose=False, grayscale=False):\n",
    "    \"\"\"Given 'imgage' this function will return a bokeh figure containing\n",
    "    - the input image\n",
    "    - rectangle boxes that have been classified a Gleason pattern\"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    if verbose: print(image.size)\n",
    "\n",
    "    # transform to cv image (maskoff uses cv2.grabCut) and flip (https://github.com/bokeh/bokeh/issues/1666)\n",
    "    img_cv = np.array(image.convert('RGB'))[::-1]\n",
    "    img = img_cv[:, :, ::-1].copy()\n",
    "\n",
    "    w, h = image.size\n",
    "    size, crds = calculateGridCoords(w, h, init_pixels=8)\n",
    "    if verbose: print('Box size', size)\n",
    "    _, _, _, coords = maskoff(img, coords=crds, box_size=size, target_dim=image.size, pixel_score=0.05)\n",
    "\n",
    "    data = [predictPatch(image, x, y, size, confidence) for x,y in coords]\n",
    "    #data = []\n",
    "    # Classify the boxes\n",
    "    #for j, coord in enumerate(coords):\n",
    "    #    x,y = coord\n",
    "    #    patch = image.crop((x, y, x+size, y+size))\n",
    "    #    c, l, preds = learn.predict(Image(T.ToTensor()(patch.convert('RGB'))))\n",
    "    #    pname = learn.data.classes[l]\n",
    "    #    tmp = dict(zip(learn.data.classes, [\"{0:.2%}\".format(p) for p in preds]))\n",
    "    #    tmp['pred'] = pname\n",
    "    #    tmp['x'] = x+size//2\n",
    "    #    tmp['y'] = y+size//2\n",
    "    #    tmp['line_clr'] = 'grey' if preds[l]<confidence else COLORMAP[pname]\n",
    "    #    data.append(tmp)\n",
    "    #    del patch\n",
    "    #end = time.time()\n",
    "    df = pd.DataFrame(data)\n",
    "    source = ColumnDataSource(data=df) \n",
    "\n",
    "    rects = Rect(x='x',y='y', width=size, height=size, line_color='line_clr', fill_color=None)\n",
    "    \n",
    "    p = bokehplotImage(image, grayscale)\n",
    "    master = p.add_glyph(source_or_glyph=source, glyph=rects)\n",
    "    master_hover = HoverTool(renderers=[master],\n",
    "                            tooltips=TOOLTIPS)\n",
    "\n",
    "    p.add_tools(master_hover)\n",
    "    p.x_range=(Range1d(0,p.plot_width))\n",
    "    p.y_range=(Range1d(0,p.plot_height))\n",
    "    if verbose: print('Took', end-start, 'to process image found', len(coords), 'patches')\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUI\n",
    "pn.extension()\n",
    "\n",
    "# defining widgets\n",
    "dpd_lang = Dropdown(options=['en', 'de'], value='en', \n",
    "                    description=TEXTS[\"dpd_lang\"][lang], layout=Layout(height='auto', width='auto'))\n",
    "btn_doc = Button(description=TEXTS[\"btn_doc\"][lang], layout=Layout(height='auto', width='auto'))\n",
    "btn_karolisnka = Button(description=TEXTS[\"btn_karolinska\"][lang], layout=Layout(height='auto', width='auto'))\n",
    "btn_radboud  = Button(description=TEXTS[\"btn_radboud\"][lang], layout=Layout(height='auto', width='auto'))\n",
    "btn_upload = FileUpload(description=TEXTS[\"btn_upload\"][lang], multiple=False, layout=Layout(height='auto', width='auto'))\n",
    "btn_header = Button(description=TEXTS[\"btn_header\"][lang], disabled=True, layout=Layout(height='auto', width='auto'))\n",
    "btn_status = Button(description=TEXTS[\"btn_status_init\"][lang], disabled=True, layout=Layout(height='auto', width='auto'))\n",
    "pre_output = Output(clear_output=True)\n",
    "output = Output(clear_output=True)\n",
    "\n",
    "# defining event functions\n",
    "def displayWaitMessage(message=TEXTS[\"btn_status_default\"][lang]):\n",
    "    btn_status.description = f'{TEXTS[\"btn_status_progress\"][lang]} {message}'\n",
    "    btn_status.style.button_color = 'yellow'\n",
    "\n",
    "def displayReadyness():\n",
    "    btn_status.description = TEXTS[\"btn_status_ready\"][lang]\n",
    "    btn_status.style.button_color = 'lightgreen'\n",
    "\n",
    "def outputImage(img):\n",
    "    with pre_output:\n",
    "        displayWaitMessage(TEXTS[\"btn_status_load\"][lang])\n",
    "        start = time.time()\n",
    "        if VERBOSE: print(img.size)\n",
    "        p = bokehplotImage(img)\n",
    "        display(pn.pane.Bokeh(p))\n",
    "        displayWaitMessage(TEXTS[\"btn_status_detect\"][lang])\n",
    "        output.clear_output()\n",
    "        end = time.time()\n",
    "        if VERBOSE: print('took', end-start, 'for displaying the image')\n",
    "        start = time.time()\n",
    "    with output:\n",
    "        p = bokehplotPatterns(img)\n",
    "        display(pn.pane.Bokeh(p))\n",
    "        pre_output.clear_output()\n",
    "        end = time.time()\n",
    "        if VERBOSE: print('took', end-start, 'for displaying the preds')\n",
    "        displayReadyness()\n",
    "    \n",
    "def processSampleImage(provider='karolinska'):\n",
    "    emptyPlot()\n",
    "    if hack_failed:\n",
    "        btn_status.description = TEXTS[\"btn_status_error\"][lang]\n",
    "        btn_status.style.button_color = 'red'\n",
    "    else:\n",
    "        start = time.time()\n",
    "        img = getSampleImageFromUrl(provider)\n",
    "        end = time.time()\n",
    "        if VERBOSE: print('took', end-start, 'for loading the image')\n",
    "        outputImage(img)\n",
    "    \n",
    "def on_btn_karolisnka_clicked(b):\n",
    "    processSampleImage(provider='karolinska')\n",
    "\n",
    "def on_btn_radboud_clicked(b):\n",
    "    processSampleImage(provider='radboud')\n",
    "\n",
    "def on_btn_doc_clicked(b):\n",
    "    output.clear_output()\n",
    "    pre_output.clear_output()\n",
    "    with output:\n",
    "        display(HTML(DOC[lang]))\n",
    "        \n",
    "def on_data_change(change):\n",
    "    emptyPlot()\n",
    "    start = time.time()\n",
    "    img = PILImage.open(io.BytesIO(btn_upload.data[-1]))\n",
    "    end = time.time()\n",
    "    if VERBOSE: print('took', end-start, 'for loading the image')\n",
    "    outputImage(img)\n",
    "    btn_upload._counter = 0\n",
    "    \n",
    "def on_lang_select(change):\n",
    "    global lang \n",
    "    lang = dpd_lang.value\n",
    "    dpd_lang.description=TEXTS[\"dpd_lang\"][lang]\n",
    "    btn_karolisnka.description=TEXTS[\"btn_karolinska\"][lang]\n",
    "    btn_radboud.description=TEXTS[\"btn_radboud\"][lang]\n",
    "    btn_upload.description=TEXTS[\"btn_upload\"][lang]\n",
    "    btn_header.description=TEXTS[\"btn_header\"][lang]\n",
    "    btn_status.description=TEXTS[\"btn_status_init\"][lang]\n",
    "    btn_doc.description=TEXTS[\"btn_doc\"][lang]\n",
    "\n",
    "# adding events\n",
    "btn_doc.on_click(on_btn_doc_clicked)\n",
    "btn_karolisnka.on_click(on_btn_karolisnka_clicked)\n",
    "btn_radboud.on_click(on_btn_radboud_clicked)\n",
    "btn_upload.observe(on_data_change, names=['data'])\n",
    "dpd_lang.observe(on_lang_select)\n",
    "\n",
    "# Layout and Style \n",
    "applayout1 = AppLayout(left_sidebar=btn_doc,\n",
    "                       right_sidebar=dpd_lang)\n",
    "applayout2 = AppLayout(header=btn_status,\n",
    "                       left_sidebar=btn_karolisnka,\n",
    "                       right_sidebar=btn_radboud,\n",
    "                       footer=btn_upload)\n",
    "btn_karolisnka.style.button_color = 'lightsalmon'\n",
    "btn_radboud.style.button_color = 'aliceblue'\n",
    "\n",
    "def emptyPlot():\n",
    "    output.clear_output()\n",
    "    pre_output.clear_output()\n",
    "    with output:\n",
    "        p = figure(sizing_mode='stretch_both',\n",
    "                   tooltips=TOOLTIPS,\n",
    "                   title=TEXTS[\"plot_title\"][lang])\n",
    "        p.plot_height = p.plot_height//2\n",
    "        display(pn.pane.Bokeh(p))\n",
    "        \n",
    "emptyPlot()\n",
    "\n",
    "display(VBox([btn_header, btn_status, applayout1, pre_output,output, applayout2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
